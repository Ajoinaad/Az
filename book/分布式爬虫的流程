1.编写普通爬虫
    创建项目
    明确目标
    创建爬虫
    保存内容
2.改造成分布式爬虫
    1.改造爬虫
        1.导入scrapy_redis中的分布式爬虫类
        2.继承类
        3.注销 start_urls & allowed——domains
        4.设置redis_key获取start_urls
        5.设置__init__获取允许的域
    2.改造配置文件
        copy配置参数

分布式爬虫总结
    使用场景
        数据量特别巨大
        数据要求时间比较紧张
    分布式爬虫的实现
        scrapy_redis 实现分布式
        普通爬虫实现分布式  实现去重集合与任务队列的共享
    分布式的部署
        穷 -- 若干台电脑普通笔记本
        小康 -- 一台服务器虚拟若干台电脑
